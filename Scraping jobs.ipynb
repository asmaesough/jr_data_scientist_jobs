{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "713ca228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\user\\anaconda\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: urllib3[secure]~=1.26 in c:\\users\\user\\anaconda\\lib\\site-packages (from selenium) (1.26.4)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\user\\anaconda\\lib\\site-packages (from selenium) (0.19.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\user\\anaconda\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: outcome in c:\\users\\user\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: idna in c:\\users\\user\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (2.10)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\user\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.14.5)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\user\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (20.3.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\user\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\user\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (2.3.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\anaconda\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\user\\anaconda\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.0.0)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in c:\\users\\user\\anaconda\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (20.0.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\anaconda\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (2020.12.5)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in c:\\users\\user\\anaconda\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (3.4.7)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\users\\user\\anaconda\\lib\\site-packages (from pyOpenSSL>=0.14->urllib3[secure]~=1.26->selenium) (1.15.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\user\\anaconda\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f662ad03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\anaconda\\lib\\site-packages (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\anaconda\\lib\\site-packages (from beautifulsoup4) (2.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdd065fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing libraries\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02432b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linkedin ID and PASSWORD\n",
    "email = \"write your email here\"\n",
    "password = \"write your password here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d42276d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-b276dae96912>:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=driver_path)\n",
      "<ipython-input-7-b276dae96912>:14: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_id('username').send_keys(email)\n",
      "<ipython-input-7-b276dae96912>:15: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_id('password').send_keys(password)\n",
      "<ipython-input-7-b276dae96912>:16: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_id('password').send_keys(Keys.RETURN)\n"
     ]
    }
   ],
   "source": [
    "## Open browser\n",
    "## You first need to download chrome driver\n",
    "driver_path = \"./chromedriver.exe\"\n",
    "driver = webdriver.Chrome(executable_path=driver_path)\n",
    "## Maximizing browser window to avoid hidden elements\n",
    "driver.set_window_size(1024, 600)\n",
    "driver.maximize_window()\n",
    "\n",
    "## Open linkedin website\n",
    "driver.get('https://www.linkedin.com/login')\n",
    "## waiting load\n",
    "time.sleep(2)\n",
    "\n",
    "## Search for login and password inputs, send credentions \n",
    "driver.find_element_by_id('username').send_keys(email)\n",
    "driver.find_element_by_id('password').send_keys(password)\n",
    "driver.find_element_by_id('password').send_keys(Keys.RETURN)\n",
    "\n",
    "## Opening jobs webpage\n",
    "## You can change the link by copying the link to the jobs you want to scrape after typing the title and location\n",
    "driver.get(f\"https://www.linkedin.com/jobs/search/?geoId=91000000&keywords=junior%20data%20scientist&location=Union%20europ%C3%A9enne\")\n",
    "## waiting load\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43fbfc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-5835f3e62e70>:12: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_xpath(f'//button[@aria-label=\"Page {i}\"]').click()\n",
      "<ipython-input-8-5835f3e62e70>:14: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  jobs_lists = driver.find_element_by_class_name('jobs-search-results__list') #here we create a list with jobs\n",
      "C:\\Users\\user\\anaconda\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:464: UserWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  warnings.warn(\"find_elements_by_* commands are deprecated. Please use find_elements() instead\")\n",
      "<ipython-input-8-5835f3e62e70>:22: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_xpath(f'//div[@aria-label=\"search results\"]/div/ul/li[{job}]/div/div[1]/div[1]/div[2]/div[1]/a').click()\n",
      "<ipython-input-8-5835f3e62e70>:26: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  size_type = driver.find_element_by_xpath(f'//div[@class=\"mt5 mb2\"]/ul/li[2]/span')\n",
      "<ipython-input-8-5835f3e62e70>:28: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  job_desc = driver.find_element_by_id('job-details')\n"
     ]
    }
   ],
   "source": [
    "## Create a list where the descriptions will be stored\n",
    "desc_list = []\n",
    "\n",
    "## each page show us some jobs, sometimes show 25, others 13 or 21 ¯\\_(ツ)_/¯\n",
    "## with this knowledge I created a loop that will check how many jobs the page is listing\n",
    "## Then \n",
    "\n",
    "## linkedin show us 40 jobs pages, then the line below will repeat 40 times\n",
    "\n",
    "for i in range(1,41):\n",
    "    ## click button to change the job list\n",
    "    driver.find_element_by_xpath(f'//button[@aria-label=\"Page {i}\"]').click()\n",
    "    ## each page show us some jobs, sometimes show 25, others 13 or 21 ¯\\_(ツ)_/¯\n",
    "    jobs_lists = driver.find_element_by_class_name('jobs-search-results__list') #here we create a list with jobs\n",
    "    jobs = jobs_lists.find_elements_by_class_name('jobs-search-results__list-item')#here we select each job to count\n",
    "    ## waiting load\n",
    "    time.sleep(1) \n",
    "    ## the loop below is for the algorithm to click exactly on the number of jobs that is showing in list\n",
    "    ## in order to avoid errors that will stop the automation\n",
    "    for job in range (1, len(jobs)+1):\n",
    "        ## job click\n",
    "        driver.find_element_by_xpath(f'//div[@aria-label=\"search results\"]/div/ul/li[{job}]/div/div[1]/div[1]/div[2]/div[1]/a').click()\n",
    "        ## waiting load \n",
    "        time.sleep(2)\n",
    "        ## select size and type of the company\n",
    "        size_type = driver.find_element_by_xpath(f'//div[@class=\"mt5 mb2\"]/ul/li[2]/span')\n",
    "        ## select job description\n",
    "        job_desc = driver.find_element_by_id('job-details')\n",
    "        ## get text\n",
    "        soup1 = BeautifulSoup(size_type.get_attribute('outerHTML'), 'html.parser')\n",
    "        soup2 = BeautifulSoup(job_desc.get_attribute('outerHTML'), 'html.parser')\n",
    "        ## add text to list\n",
    "        desc_list.append([soup1.text, soup2.text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2b00f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "459"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Count the number of jobs scraped\n",
    "len(desc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4069fe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "## Create dictionnary\n",
    "data = {'job_description': [x[1] for x in disc_list],\n",
    "        'size_type': [x[0] for x in disc_list]}\n",
    " \n",
    "## Create DataFrame\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58a72668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_description</th>\n",
       "      <th>size_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n\\n \\n              We are proud to belong ...</td>\n",
       "      <td>\\n201-500 employees · Computer Games\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n\\n \\nJob Description\\n\\nJob Description\\n ...</td>\n",
       "      <td>\\n5,001-10,000 employees · Motor Vehicle Manuf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\n \\n              This role is accountabl...</td>\n",
       "      <td>\\n10,001+ employees · Telecommunications\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\n\\n \\n              Everything happens some...</td>\n",
       "      <td>\\n51-200 employees · Internet Publishing\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\n\\n \\nJob Responsibilities\\n Process data a...</td>\n",
       "      <td>\\n10,001+ employees · Semiconductor Manufactur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     job_description  \\\n",
       "0  \\n\\n\\n \\n              We are proud to belong ...   \n",
       "1  \\n\\n\\n \\nJob Description\\n\\nJob Description\\n ...   \n",
       "2  \\n\\n\\n \\n              This role is accountabl...   \n",
       "3  \\n\\n\\n \\n              Everything happens some...   \n",
       "4  \\n\\n\\n \\nJob Responsibilities\\n Process data a...   \n",
       "\n",
       "                                           size_type  \n",
       "0             \\n201-500 employees · Computer Games\\n  \n",
       "1  \\n5,001-10,000 employees · Motor Vehicle Manuf...  \n",
       "2         \\n10,001+ employees · Telecommunications\\n  \n",
       "3         \\n51-200 employees · Internet Publishing\\n  \n",
       "4  \\n10,001+ employees · Semiconductor Manufactur...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392ac94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split size and type and transform them to 2 separated columns\n",
    "df = pd.concat([df, df['size_type'].str.split(pat = '·', expand = True)], axis=1)\n",
    "## Rename the new columns\n",
    "df.rename(columns = {0:'size', 1:'activity'}, inplace = True)\n",
    "## Drop old column\n",
    "df.drop(['size_type'], axis=1, inplace=True)\n",
    "## Drop duplicates\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fb4b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save csv\n",
    "df.to_csv('jobs.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
